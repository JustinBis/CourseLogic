scraper.js will read "/scrapers/" directory for all .js files
then require all .js files and asynchonously run them by calling the "main()" method which then returns a properly formatted javascript object of the form:

{
	schoolID: "UF", // Text string uniquely identifying the school
	schoolName: "University of Florida", // Full school name
	subjects: 
		[{
			subjectID: "ACG",
			subjectName: "Accounting"
		},
		{
			subjectID: "COP",
			subjectName: "Computer and Information Science and Engineering"
		}],
	classTopics:
		[{
			subjectID: "COP",
			classID: "COP 3502",
			className: "Programming Fundamentals 1"
		},
		{
			subjectID: "COP",
			classID: "COP 3503",
			className: "Programming Fundamentals 2"
		}],
	classOptions:
		[{
			"crn": 11792" // CRN, uniquely identifying the section
			"classID": "COP 3503" // Links back to classTopics
			"prof": "Elizabeth G. Miller",
			"times": 
				[{
					"days": "MWF", 
					"location": "Lowder Hall 110", 
					"time": "8:00 am - 8:50 am", 
					"type": "Class"
				}]
		},
		{
			"crn": "2AB0"
			"classID": "COP 3503"
			"prof": "Dr. Mr. Professor II, esq.", 
			"times": 
				[{
					"days": "MWF", 
					"location": "Lowder Hall 110", 
					"time": "9:00 am - 9:50 am", 
					"type": "Class"
				}]
		}]

}